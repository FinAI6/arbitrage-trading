# arb_trading/utils/performance.py (ìƒì„¸ ë¡œê¹… ì¶”ê°€)
import time
import psutil
import threading
import os
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from collections import defaultdict, deque
import logging


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„°"""
    # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
    fetch_times: deque = field(default_factory=lambda: deque(maxlen=100))
    spread_calc_times: deque = field(default_factory=lambda: deque(maxlen=100))

    # ê±°ë˜ì†Œë³„ ì„¸ë¶€ ì‹œê°„
    exchange_fetch_times: Dict[str, deque] = field(default_factory=lambda: defaultdict(lambda: deque(maxlen=100)))

    # API í˜¸ì¶œ í†µê³„
    api_call_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    error_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))

    # í”„ë¡œì„¸ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    process_cpu_usage: deque = field(default_factory=lambda: deque(maxlen=50))
    process_memory_usage: deque = field(default_factory=lambda: deque(maxlen=50))
    process_memory_mb: deque = field(default_factory=lambda: deque(maxlen=50))


@dataclass
class FetchTiming:
    """ê°œë³„ Fetch íƒ€ì´ë° ì •ë³´"""
    exchange: str
    operation: str  # 'tickers', 'volumes', 'symbols'
    duration: float
    timestamp: float
    success: bool
    error_msg: str = ""


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""

    def __init__(self, enabled: bool = False):
        self.enabled = enabled
        self.metrics = PerformanceMetrics()
        self._start_time = time.time()
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_monitoring = threading.Event()
        self._process = None
        self.logger = logging.getLogger(__name__)

        # ìƒì„¸ ë¡œê¹…ìš©
        self._current_fetch_timings: List[FetchTiming] = []

        if self.enabled:
            try:
                self._process = psutil.Process(os.getpid())
                self.start_process_monitoring()
                self.logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ìƒì„¸ ë¡œê¹… í™œì„±í™”)")
            except Exception as e:
                self.logger.warning(f"í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def start_process_monitoring(self):
        """í”„ë¡œì„¸ìŠ¤ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""

        def monitor():
            while not self._stop_monitoring.is_set():
                try:
                    if self._process and self._process.is_running():
                        cpu_percent = self._process.cpu_percent(interval=0.1)
                        self.metrics.process_cpu_usage.append(cpu_percent)

                        memory_info = self._process.memory_info()
                        memory_mb = memory_info.rss / 1024 / 1024
                        total_memory = psutil.virtual_memory().total
                        memory_percent = (memory_info.rss / total_memory) * 100

                        self.metrics.process_memory_usage.append(memory_percent)
                        self.metrics.process_memory_mb.append(memory_mb)

                    time.sleep(2)

                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    break
                except Exception:
                    time.sleep(1)

        self._monitoring_thread = threading.Thread(target=monitor, daemon=True)
        self._monitoring_thread.start()

    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self._stop_monitoring.set()
        if self._monitoring_thread:
            self._monitoring_thread.join(timeout=2)

    def start_fetch_cycle(self):
        """Fetch ì‚¬ì´í´ ì‹œì‘ (íƒ€ì´ë° ì´ˆê¸°í™”)"""
        if self.enabled:
            self._current_fetch_timings.clear()

    def record_exchange_fetch(self, exchange: str, operation: str, duration: float,
                              success: bool = True, error_msg: str = ""):
        """ê±°ë˜ì†Œë³„ fetch ì‹œê°„ ê¸°ë¡"""
        if self.enabled:
            # ìƒì„¸ íƒ€ì´ë° ì •ë³´ ì €ì¥
            timing = FetchTiming(
                exchange=exchange,
                operation=operation,
                duration=duration,
                timestamp=time.time(),
                success=success,
                error_msg=error_msg
            )
            self._current_fetch_timings.append(timing)

            # ê±°ë˜ì†Œë³„ ì‹œê°„ ì €ì¥
            self.metrics.exchange_fetch_times[exchange].append(duration)

            # ìƒì„¸ ë¡œê¹…
            status = "âœ…" if success else "âŒ"
            self.logger.info(
                f"ğŸ“Š {status} {exchange.upper()} {operation}: {duration:.3f}ì´ˆ"
                f"{f' (ì˜¤ë¥˜: {error_msg})' if error_msg else ''}"
            )

    def record_fetch_time(self, duration: float):
        """ì „ì²´ ë°ì´í„° í˜ì¹˜ ì‹œê°„ ê¸°ë¡"""
        if self.enabled:
            self.metrics.fetch_times.append(duration)

            # ê±°ë˜ì†Œë³„ ìƒì„¸ ë¡œê¹…
            if self._current_fetch_timings:
                self.logger.info(f"ğŸ”„ ì „ì²´ ë°ì´í„° í˜ì¹˜ ì™„ë£Œ: {duration:.3f}ì´ˆ")

                # ê±°ë˜ì†Œë³„ ë¶„ì„
                exchange_summary = defaultdict(list)
                for timing in self._current_fetch_timings:
                    exchange_summary[timing.exchange].append(timing.duration)

                for exchange, durations in exchange_summary.items():
                    total_time = sum(durations)
                    avg_time = total_time / len(durations)
                    self.logger.info(
                        f"  ğŸ“ˆ {exchange.upper()}: {total_time:.3f}ì´ˆ "
                        f"(í‰ê· : {avg_time:.3f}ì´ˆ, í˜¸ì¶œ: {len(durations)}íšŒ)"
                    )

    def record_spread_calc_time(self, duration: float, symbols_count: int = 0):
        """ìŠ¤í”„ë ˆë“œ ê³„ì‚° ì‹œê°„ ê¸°ë¡"""
        if self.enabled:
            self.metrics.spread_calc_times.append(duration)

            # ìƒì„¸ ë¡œê¹…
            if symbols_count > 0:
                per_symbol = duration / symbols_count * 1000  # ms per symbol
                self.logger.info(
                    f"âš¡ ìŠ¤í”„ë ˆë“œ ê³„ì‚° ì™„ë£Œ: {duration:.3f}ì´ˆ "
                    f"({symbols_count}ê°œ ì‹¬ë³¼, ì‹¬ë³¼ë‹¹ {per_symbol:.1f}ms)"
                )
            else:
                self.logger.info(f"âš¡ ìŠ¤í”„ë ˆë“œ ê³„ì‚° ì™„ë£Œ: {duration:.3f}ì´ˆ")

    def record_total_cycle_time(self, total_duration: float, fetch_duration: float,
                                calc_duration: float, symbols_processed: int):
        """ì „ì²´ ì‚¬ì´í´ ì‹œê°„ ê¸°ë¡ ë° ìƒì„¸ ë¡œê¹…"""
        if self.enabled:
            overhead = total_duration - fetch_duration - calc_duration

            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ¯ ìŠ¤í”„ë ˆë“œ ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´ ì™„ë£Œ")
            self.logger.info(f"   ì „ì²´ ì‹œê°„: {total_duration:.3f}ì´ˆ")
            self.logger.info(f"   â”œâ”€ ë°ì´í„° í˜ì¹˜: {fetch_duration:.3f}ì´ˆ ({fetch_duration / total_duration * 100:.1f}%)")
            self.logger.info(f"   â”œâ”€ ìŠ¤í”„ë ˆë“œ ê³„ì‚°: {calc_duration:.3f}ì´ˆ ({calc_duration / total_duration * 100:.1f}%)")
            self.logger.info(f"   â””â”€ ê¸°íƒ€ ì²˜ë¦¬: {overhead:.3f}ì´ˆ ({overhead / total_duration * 100:.1f}%)")
            self.logger.info(f"   ì²˜ë¦¬ëœ ì‹¬ë³¼: {symbols_processed}ê°œ")

            if symbols_processed > 0:
                throughput = symbols_processed / total_duration
                self.logger.info(f"   ì²˜ë¦¬ ì„±ëŠ¥: {throughput:.1f} ì‹¬ë³¼/ì´ˆ")

            self.logger.info("=" * 60)

    def record_api_call(self, exchange: str):
        """API í˜¸ì¶œ íšŸìˆ˜ ê¸°ë¡"""
        if self.enabled:
            self.metrics.api_call_counts[exchange] += 1

    def record_error(self, error_type: str):
        """ì—ëŸ¬ ë°œìƒ ê¸°ë¡"""
        if self.enabled:
            self.metrics.error_counts[error_type] += 1

    def get_exchange_performance_summary(self) -> Dict[str, Any]:
        """ê±°ë˜ì†Œë³„ ì„±ëŠ¥ ìš”ì•½"""
        if not self.enabled:
            return {}

        summary = {}
        for exchange, times in self.metrics.exchange_fetch_times.items():
            if times:
                summary[exchange] = {
                    "í‰ê·  ì‘ë‹µì‹œê°„": f"{sum(times) / len(times):.3f}ì´ˆ",
                    "ìµœê·¼ 10íšŒ í‰ê· ": f"{sum(list(times)[-10:]) / min(10, len(times)):.3f}ì´ˆ",
                    "ìµœì†Œ ì‹œê°„": f"{min(times):.3f}ì´ˆ",
                    "ìµœëŒ€ ì‹œê°„": f"{max(times):.3f}ì´ˆ",
                    "ì´ í˜¸ì¶œ íšŸìˆ˜": len(times)
                }

        return summary

    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        if not self.enabled:
            return {"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§": "ë¹„í™œì„±í™”ë¨"}

        summary = {
            # "ì‹¤í–‰ ì‹œê°„": f"{time.time() - self._start_time:.1f}ì´ˆ",
            "ì „ì²´ ì„±ëŠ¥": {
                "ë°ì´í„° í˜ì¹˜ í‰ê· ": f"{sum(self.metrics.fetch_times) / len(self.metrics.fetch_times):.3f}ì´ˆ" if self.metrics.fetch_times else "N/A",
                # "ìŠ¤í”„ë ˆë“œ ê³„ì‚° í‰ê· ": f"{sum(self.metrics.spread_calc_times) / len(self.metrics.spread_calc_times):.3f}ì´ˆ" if self.metrics.spread_calc_times else "N/A",
                # "ì´ ì‚¬ì´í´ ìˆ˜": len(self.metrics.fetch_times)
            },
            "ê±°ë˜ì†Œë³„ ì„±ëŠ¥": self.get_exchange_performance_summary(),
            # "API í˜¸ì¶œ í†µê³„": dict(self.metrics.api_call_counts),
            "ì—ëŸ¬ ë°œìƒ í†µê³„": dict(self.metrics.error_counts)
        }

        # í”„ë¡œì„¸ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë³´
        if self.metrics.process_cpu_usage and self.metrics.process_memory_mb:
            avg_cpu = sum(self.metrics.process_cpu_usage) / len(self.metrics.process_cpu_usage)
            current_memory = self.metrics.process_memory_mb[-1] if self.metrics.process_memory_mb else 0

            summary["í”„ë¡œì„¸ìŠ¤ ë¦¬ì†ŒìŠ¤"] = {
                "í‰ê·  CPU": f"{avg_cpu:.1f}%",
                "í˜„ì¬ ë©”ëª¨ë¦¬": f"{current_memory:.1f} MB"
            }

        return summary
